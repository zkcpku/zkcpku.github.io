---
layout: default
---

<img align="left" src="assets/photo.png" hspace="5">

Hi there! I'm currently pursuing my Ph.D. at Peking University, with an expected graduation in June 2026. 

My research focuses on **AI4SE**, **LLMs for Code**, and **Code Generation and Representation through deep learning techniques**.

I am passionate about exploring the intersection of artificial intelligence and software engineering, particularly how large language models can enhance code generation and representation.

---

## Personal Information

**Name:** Kechi Zhang (张克驰)  
**Address:** Room No. 1726, No. 1 Science Building, Peking University, No. 5 Yiheyuan Road, Haidian District, 100871 Beijing  
**Email:** [zhangkechi@pku.edu.cn](mailto:zhangkechi@pku.edu.cn)  
**Homepage:** [Google Scholar](https://scholar.google.com/citations?user=6AuwtXwAAAAJ)

![Profile Photo](DSC_079.jpg)

---

## Education

- **Ph.D.**  
  School of Computer Science, Peking University, Beijing, China  
  **Duration:** Sept. 2021 - July 2026 (expected)  
  **Major:** Computer Software and Theory -- Intelligent Software and Requirement Engineering  
  **Tutor:** Professor Zhi Jin  
  **Assistant Tutor:** Professor Ge Li

- **B.S.**  
  School of EECS, Peking University, Beijing, China  
  **Duration:** Sept. 2017 - July 2021  
  **Major:** Computer Science and Technology  
  **GPA:** ~3.60 (Top 25%)

---

## Research Direction

**AI4SE & LLMs for Code**

- **Code Generation and Code Representation Based on Deep Learning**
  - Pre-training, fine-tuning, and alignment of Code LLMs
  - Tool Enhancement, Agent Technology, and Length Extrapolation for Code Models
  - Project-level Code Generation
  - Code Representation Model based on Structural Information

---

## Main Research Papers

- **CodeAgent**  
  *ACL 2024 Main Conference*  
  - Code generation work proposing a method to integrate multiple programming assistance tools into large models to solve practical programming problems

- **HiRoPE**  
  *ACL 2024 Main Conference*  
  - Work on length extrapolation in large code models, proposing a plug-and-play length extension method that requires no training

- **Self-Edit**  
  *ACL 2023 Main Conference*  
  - Code generation work, one of the earliest explorations into the self-repair capability of large models in code generation

- **Hierarchy Transformer**  
  *ICPC 2023*  
  *ACM SIGSOFT Distinguished Paper Award*  
  - Code representation work, proposing an improved Transformer structure for jointly modeling sequence information and structural information in source code

- **Heterogeneous Code GNN**  
  *ICPC 2022*  
  - Code representation work, proposing a heterogeneous graph representation model for programs, HGT-HPG, to model the graph structure information in code

- **ToolCoder**  
  - Code generation work proposing a tool-enhanced learning method that embeds external API search tools (internet search engines and document search tools) into the code generation model

- **Code Generation Survey**  
  *SCIS 2024, CCF-A*  
  - A comprehensive survey of code generation, summarizing related work in the field

---

## Rewards & Honors

- 2023 ACM SIGSOFT Distinguished Paper Award
- Peking University Outstanding Student Award, 2022 and 2023
- 2023 Peking University Yongying Foundation Scholarship
- Peking University Excellent Research Award, 2017-2021
- Peking University EECS Scholarship, 2017-2021
- 2020 Peking University Schlumberger Scholarship

---

Have a look at my [publications](/publications/).
